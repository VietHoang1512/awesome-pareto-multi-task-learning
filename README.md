# awesome-pareto-multi-task-learning
A collection of AWESOME papers on multi-task learning with multiobjective optimization setup

## Paper
### Preprint
 - Controllable Pareto Multi-Task Learning [[arxiv 2021](https://arxiv.org/pdf/2010.06313.pdf)] [[Pytorch](https://openreview.net/attachment?id=5mhViEOQxaV&name=supplementary_material)]
 - Follow the bisector: a simple method for multi-objective optimization github [[arxiv 2020](https://arxiv.org/abs/2007.06937)] [[code](https://github.com/amkatrutsa/edm)]
 - Multi-Objective Learning to Predict Pareto Fronts Using Hypervolume Maximization [[arxiv 2021](https://arxiv.org/pdf/2102.04523.pdf)] [[code](https://github.com/timodeist/multi_objective_learning)]
 - Self-Evolutionary Optimization for Pareto Front Learning [[arxiv 2021](https://arxiv.org/pdf/2110.03461.pdf)]
 - Pareto Navigation Gradient Descent: a First-Order Algorithm for Optimization in Pareto Set [[arxiv 2021](https://arxiv.org/pdf/2110.08713)]
 - Fast Line Search for Multi-Task Learning [[arxiv 2021](https://arxiv.org/abs/2110.00874)]
 - A Hybrid 2-stage Neural Optimization for Pareto Front Extraction [[arxiv 2021](https://arxiv.org/abs/2101.11684)] [[code](https://openreview.net/attachment?id=UOj0MV__Cr&name=supplementary_material)]
 - Scalable Unidirectional Pareto Optimality for Multi-Task Learning with Constraints [[arxiv 2021](https://arxiv.org/abs/2110.15442)]
 - Stochastic Multiple Target Sampling Gradient Descent [[arxiv 2022](https://arxiv.org/abs/2206.01934?fbclid=IwAR0DctSaeZhpvgJeYZO1RNCxCy4DR-PSB65qKOFklALv2rCyUw6W2sNAssw)]

### Conference
 - Multi-Task Learning as Multi-Objective Optimization [[NIPS 2018](https://arxiv.org/pdf/1810.04650.pdf)] [[Pytorch](https://github.com/isl-org/MultiObjectiveOptimization)]
 - Pareto Multi-Task Learning  [[NeurIPS 2019](https://proceedings.neurips.cc/paper/2019/file/685bfde03eb646c27ed565881917c71c-Paper.pdf)] [[Pytorch](https://github.com/Xi-L/ParetoMTL)]
 - Effcient Continuous Pareto Exploration in Multi-Task Learning [[ICML 2020](http://proceedings.mlr.press/v119/ma20a/ma20a.pdf)] [[Pytorch](https://github.com/mit-gfx/ContinuousParetoMTL)]
 - Multi-Task Learning with User Preferences Gradient Descent with Controlled Ascent in Pareto Optimization [[ICML 2020](http://proceedings.mlr.press/v119/mahapatra20a/mahapatra20a.pdf)] [[Pytorch](https://github.com/dbmptr/EPOSearch)]
 - Learning the pareto front with hypernetworks [[ICLR 2021](https://arxiv.org/pdf/2010.04104.pdf)] [[code](https://github.com/AvivNavon/pareto-hypernetworks)]
 - Profiling Pareto Front With Multi-Objective Stein Variational Gradient Descent [[NeurIPS 2021 (Spotlight)](https://proceedings.neurips.cc/paper/2021/file/7bb16972da003e87724f048d76b7e0e1-Paper.pdf)] [[Pytorch](https://github.com/gnobitab/MultiObjectiveSampling)]
 - Scalable Pareto Front Approximation for Deep Multi-Objective Learning [[ICDM 2021](https://128.84.4.13/pdf/2103.13392.pdf)] [[Pytorch](https://github.com/ruchtem/cosmos)]
 - Learning with Privileged Tasks [[ICCV 2021](https://openaccess.thecvf.com/content/ICCV2021/html/Song_Learning_With_Privileged_Tasks_ICCV_2021_paper.html)] 
### Library
 - [pymoo](https://pymoo.org/)
